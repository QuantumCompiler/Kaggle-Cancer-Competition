%----------------------------------------------------------------------------------------
%	PACKAGES AND OTHER DOCUMENT CONFIGURATIONS
%----------------------------------------------------------------------------------------

\documentclass[
	a4paper, % Paper size, use either a4paper or letterpaper
	10pt, % Default font size, can also use 11pt or 12pt, although this is not recommended
	unnumberedsections, % Comment to enable section numbering
	twoside, % Two side traditional mode where headers and footers change between odd and even pages, comment this option to make them fixed
]{LTJournalArticle}

\addbibresource{sample.bib} % BibLaTeX bibliography file

\runninghead{Shortened Running Article Title} % A shortened article title to appear in the running head, leave this command empty for no running head

\footertext{\textit{Journal of Biological Sampling} (2024) 12:533-684} % Text to appear in the footer, leave this command empty for no footer text

\setcounter{page}{1} % The page number of the first page, set this to a higher number if the article is to be part of an issue or larger work

%----------------------------------------------------------------------------------------
%	TITLE SECTION
%----------------------------------------------------------------------------------------

\title{CSPB 3202 HW 5 - Kaggle Competition\\} % Article title, use manual lines breaks (\\) to beautify the layout

% Authors are listed in a comma-separated list with superscript numbers indicating affiliations
% \thanks{} is used for any text that should be placed in a footnote on the first page, such as the corresponding author's email, journal acceptance dates, a copyright/license notice, keywords, etc
\author{%
	Taylor Larrechea
}

% Affiliations are output in the \date{} command
\date{\footnotesize\ The University Of Colorado Boulder, College Of Engineering And Applied Science}

% Full-width abstract
\renewcommand{\maketitlehookd}{
	\begin{abstract}
		This assignment focuses on training a Machine Learning model that can accurately classify images that represent cancer. For this model, the python package \textit{Tensorflow} was used to train the model.
		This article will discuss the methodology used to train the model, the results of the model, and the conclusions that can be drawn from the results.
	\end{abstract}
}

%----------------------------------------------------------------------------------------

\begin{document}

\maketitle % Output the title section

%----------------------------------------------------------------------------------------
%	ARTICLE CONTENTS
%----------------------------------------------------------------------------------------

\section{Imports}

The first step that was used in creating a model to classify images was to import the necessary libraries. The libraries that were imported and used in this model were:

\begin{itemize}
	\item \textbf{pandas}
	\item \textbf{tensorflow}
	\begin{itemize}
		\item \textbf{keras.preprocessing.image} - ImageDataGenerator: A class that generates batches of tensor image data with real-time data augmentation.
		\item \textbf{keras.applications} - ResNet50: A pre-trained model that can be used to classify images.
		\item \textbf{keras.models} - Model: A class that groups layers into an object with training and inference features.
		\item \textbf{keras.layers}
		\begin{itemize}
			\item \textbf{GlobalAveragePooling2D}: A class that applies average pooling on the spatial dimensions until each spatial dimension is one.
			\item \textbf{Dense}: A class that implements the operation: output = activation(dot(input, kernel) + bias) where activation is the element-wise activation function passed as the activation 
			argument, kernel is a weights matrix created by the layer, and bias is a bias vector created by the layer (only applicable if use\_bias is True).
			\item \textbf{Input}: A class that is used to instantiate a Keras tensor.
		\end{itemize}
		\item \textbf{keras.callbacks}:
		\begin{itemize}
			\item \textbf{ModelCheckpoint}: A class that saves the model after every epoch.
		\end{itemize}
	\end{itemize}
\end{itemize}

Once these models were imported, the model was now set to be trained.

\section{Model Training}

To begin training this model, the first step was to get the data from the CSV file that was provided by Kaggle.

\subsection{Data Preprocessing}

The name of the CSV file that was provided was \textit{train\_labels.csv}. This file was loaded into a pandas DataFrame where label was loaded into one column and the image ID was loaded into another
column.

This data was then split into a training and validation set. The training set was 80\% of the data and the validation set was 20\% of the data. The intention of using a validation set was an attempt to
prevent overfitting of the model.

\subsection{Data Augmentation}

The next step was to then augment the data that was loaded. This was done using the \textit{ImageDataGenerator} class from the \textit{keras.preprocessing.image} module. This class was used to generate
batches of tensor image data with real-time data augmentation. The data augmentation that was used was to rescale the images by 1/255, rotate the images by 20 degrees, zoom the images by 20\%, and flip
the images horizontally.

\subsection{Model Creation}

After the data was processed and then subsequently augmented, the next step was to create the model. The model that was used was the ResNet50 model from the \textit{keras.applications} module. This model
was used because it is a pre-trained model that can be used to classify images. The model was then set to be trained on the training data. This model was then trained with a total of 10 epochs. The results
of each subsequent epoch were saved using the \textit{ModelCheckpoint} class from the \textit{keras.callbacks} module. This model was then saved using the \textit{model.save()} method. 

\section{Model Results}

After the model was created, the next step was to evaluate the model. This was achieved by loading the saved model that was previously created and evaluating it in a separate file.

\end{document}
